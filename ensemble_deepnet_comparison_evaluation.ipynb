{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas import DataFrame, read_csv\n",
    "import bigml.api\n",
    "from bigml.api import BigML\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = BigML(project='project/5dbc4cc1f80b1640d7002229')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we retrieve our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigml_infos =read_csv(r'dataset_deepnet_ensemble/bigml/bigml_data_models_informations.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = bigml_infos['datasets']['dataset1']\n",
    "dataset2 = bigml_infos['datasets']['dataset2']\n",
    "dataset3 = bigml_infos['datasets']['dataset3']\n",
    "dataset4 = bigml_infos['datasets']['dataset4']\n",
    "dataset5 = bigml_infos['datasets']['dataset5']\n",
    "dataset6 = bigml_infos['datasets']['dataset6']\n",
    "dataset7 = bigml_infos['datasets']['dataset7']\n",
    "dataset8 = bigml_infos['datasets']['dataset8']\n",
    "dataset9 = bigml_infos['datasets']['dataset9']\n",
    "dataset10 = bigml_infos['datasets']['dataset10']\n",
    "dataset11 = bigml_infos['datasets']['dataset11']\n",
    "dataset12 = bigml_infos['datasets']['dataset12']\n",
    "dataset13 = bigml_infos['datasets']['dataset13']\n",
    "dataset14 = bigml_infos['datasets']['dataset14']\n",
    "dataset15 = bigml_infos['datasets']['dataset15']\n",
    "dataset16 = bigml_infos['datasets']['dataset16']\n",
    "dataset17 = bigml_infos['datasets']['dataset17']\n",
    "dataset18 = bigml_infos['datasets']['dataset18']\n",
    "dataset19 = bigml_infos['datasets']['dataset19']\n",
    "dataset20 = bigml_infos['datasets']['dataset20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble1 = bigml_infos['ensembles']['dataset1']\n",
    "ensemble2 = bigml_infos['ensembles']['dataset2']\n",
    "ensemble3 = bigml_infos['ensembles']['dataset3']\n",
    "ensemble4 = bigml_infos['ensembles']['dataset4']\n",
    "ensemble5 = bigml_infos['ensembles']['dataset5']\n",
    "ensemble6 = bigml_infos['ensembles']['dataset6']\n",
    "ensemble7 = bigml_infos['ensembles']['dataset7']\n",
    "ensemble8 = bigml_infos['ensembles']['dataset8']\n",
    "ensemble9 = bigml_infos['ensembles']['dataset9']\n",
    "ensemble10 = bigml_infos['ensembles']['dataset10']\n",
    "ensemble11 = bigml_infos['ensembles']['dataset11']\n",
    "ensemble12 = bigml_infos['ensembles']['dataset12']\n",
    "ensemble13 = bigml_infos['ensembles']['dataset13']\n",
    "ensemble14 = bigml_infos['ensembles']['dataset14']\n",
    "ensemble15 = bigml_infos['ensembles']['dataset15']\n",
    "ensemble16 = bigml_infos['ensembles']['dataset16']\n",
    "ensemble17 = bigml_infos['ensembles']['dataset17']\n",
    "ensemble18 = bigml_infos['ensembles']['dataset18']\n",
    "ensemble19 = bigml_infos['ensembles']['dataset19']\n",
    "ensemble20 = bigml_infos['ensembles']['dataset20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet1 = bigml_infos['deepnets']['dataset1']\n",
    "deepnet2 = bigml_infos['deepnets']['dataset2']\n",
    "deepnet3 = bigml_infos['deepnets']['dataset3']\n",
    "deepnet4 = bigml_infos['deepnets']['dataset4']\n",
    "deepnet5 = bigml_infos['deepnets']['dataset5']\n",
    "deepnet6 = bigml_infos['deepnets']['dataset6']\n",
    "deepnet7 = bigml_infos['deepnets']['dataset7']\n",
    "deepnet8 = bigml_infos['deepnets']['dataset8']\n",
    "deepnet9 = bigml_infos['deepnets']['dataset9']\n",
    "deepnet10 = bigml_infos['deepnets']['dataset10']\n",
    "deepnet11 = bigml_infos['deepnets']['dataset11']\n",
    "deepnet12 = bigml_infos['deepnets']['dataset12']\n",
    "deepnet13 = bigml_infos['deepnets']['dataset13']\n",
    "deepnet14 = bigml_infos['deepnets']['dataset14']\n",
    "deepnet15 = bigml_infos['deepnets']['dataset15']\n",
    "deepnet16 = bigml_infos['deepnets']['dataset16']\n",
    "deepnet17 = bigml_infos['deepnets']['dataset17']\n",
    "deepnet18 = bigml_infos['deepnets']['dataset18']\n",
    "deepnet19 = bigml_infos['deepnets']['dataset19']\n",
    "deepnet20 = bigml_infos['deepnets']['dataset20']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We create ours BigMl data set\n",
    "\n",
    "* we create source from csv file\n",
    "* we create the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We create the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_source = api.create_source(\"testset/testset_dataframe3.csv\")\n",
    "api.ok(test_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'source/5dbdbd80e47684746800f9e2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_source_id = test_source['resource']\n",
    "test_source_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = api.create_dataset(test_source)\n",
    "api.ok(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset/5dbdbeafe47684746800f9e8'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_id = test_dataset['resource']\n",
    "test_dataset_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We get the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations = []\n",
    "ensemble_test_evaluations = []\n",
    "ensemble_train_accuracy = []\n",
    "ensemble_train_auc = []\n",
    "ensemble_test_accuracy = []\n",
    "ensemble_test_auc = []\n",
    "\n",
    "deepnet_train_evaluations = []\n",
    "deepnet_test_evaluations = []\n",
    "deepnet_train_accuracy = []\n",
    "deepnet_train_auc = []\n",
    "deepnet_test_auc = []\n",
    "deepnet_test_accuracy = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train1 = api.create_evaluation(ensemble1, dataset1)\n",
    "api.ok(evaluation_ensemble_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train1['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train1['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train1['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test1 = api.create_evaluation(ensemble1, test_dataset)\n",
    "api.ok(evaluation_ensemble_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test1['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test1['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test1['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train1 = api.create_evaluation(deepnet1, dataset1)\n",
    "api.ok(evaluation_deepnet_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train1['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train1['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train1['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test1 = api.create_evaluation(deepnet1, test_dataset)\n",
    "api.ok(evaluation_deepnet_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test1['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test1['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test1['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train2 = api.create_evaluation(ensemble2, dataset2)\n",
    "api.ok(evaluation_ensemble_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train2['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train2['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train2['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test2 = api.create_evaluation(ensemble2, test_dataset)\n",
    "api.ok(evaluation_ensemble_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test2['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test2['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test2['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train2 = api.create_evaluation(deepnet2, dataset2)\n",
    "api.ok(evaluation_deepnet_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train2['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train2['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train2['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test2 = api.create_evaluation(deepnet2, test_dataset)\n",
    "api.ok(evaluation_deepnet_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test2['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test2['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test2['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train3 = api.create_evaluation(ensemble3, dataset3)\n",
    "api.ok(evaluation_ensemble_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train3['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train3['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train3['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test3 = api.create_evaluation(ensemble3, test_dataset)\n",
    "api.ok(evaluation_ensemble_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test3['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test3['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test3['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train3 = api.create_evaluation(deepnet3, dataset3)\n",
    "api.ok(evaluation_deepnet_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train3['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train3['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train3['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test3 = api.create_evaluation(deepnet3, test_dataset)\n",
    "api.ok(evaluation_deepnet_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test3['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test3['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test3['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train4 = api.create_evaluation(ensemble4, dataset4)\n",
    "api.ok(evaluation_ensemble_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train4['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train4['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train4['object']['result']['model']['average_area_under_roc_curve'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test4 = api.create_evaluation(ensemble4, test_dataset)\n",
    "api.ok(evaluation_ensemble_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test4['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test4['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test4['object']['result']['model']['average_area_under_roc_curve'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "evaluation_deepnet_train4 = api.create_evaluation(deepnet4, dataset4)\n",
    "api.ok(evaluation_deepnet_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train4['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train4['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train4['object']['result']['model']['average_area_under_roc_curve'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test4 = api.create_evaluation(deepnet4, test_dataset)\n",
    "api.ok(evaluation_deepnet_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test4['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test4['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test4['object']['result']['model']['average_area_under_roc_curve'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train5 = api.create_evaluation(ensemble5, dataset5)\n",
    "api.ok(evaluation_ensemble_train5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train5['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train5['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train5['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test5 = api.create_evaluation(ensemble5, test_dataset)\n",
    "api.ok(evaluation_ensemble_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test5['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test5['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test5['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train5 = api.create_evaluation(deepnet5, dataset5)\n",
    "api.ok(evaluation_deepnet_train5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train5['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train5['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train5['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test5 = api.create_evaluation(deepnet5, test_dataset)\n",
    "api.ok(evaluation_deepnet_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test5['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test5['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test5['object']['result']['model']['average_area_under_roc_curve'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train6 = api.create_evaluation(ensemble6, dataset6)\n",
    "api.ok(evaluation_ensemble_train6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train6['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train6['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train6['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test6 = api.create_evaluation(ensemble6, test_dataset)\n",
    "api.ok(evaluation_ensemble_test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test6['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test6['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test6['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train6 = api.create_evaluation(deepnet6, dataset6)\n",
    "api.ok(evaluation_deepnet_train6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train6['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train6['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train6['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test6 = api.create_evaluation(deepnet6, test_dataset)\n",
    "api.ok(evaluation_deepnet_test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test6['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test6['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test6['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train7 = api.create_evaluation(ensemble7, dataset7)\n",
    "api.ok(evaluation_ensemble_train7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train7['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train7['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train7['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test7 = api.create_evaluation(ensemble7, test_dataset)\n",
    "api.ok(evaluation_ensemble_test7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test7['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test7['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test7['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train7 = api.create_evaluation(deepnet7, dataset7)\n",
    "api.ok(evaluation_deepnet_train7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train7['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train7['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train7['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test7 = api.create_evaluation(deepnet7, test_dataset)\n",
    "api.ok(evaluation_deepnet_test7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test7['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test7['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test7['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train8 = api.create_evaluation(ensemble8, dataset8)\n",
    "api.ok(evaluation_ensemble_train8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train8['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train8['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train8['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test8 = api.create_evaluation(ensemble8, test_dataset)\n",
    "api.ok(evaluation_ensemble_test8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test8['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test8['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test8['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train8 = api.create_evaluation(deepnet8, dataset8)\n",
    "api.ok(evaluation_deepnet_train8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train8['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train8['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train8['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test8 = api.create_evaluation(deepnet8, test_dataset)\n",
    "api.ok(evaluation_deepnet_test8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test8['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test8['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test8['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train9 = api.create_evaluation(ensemble9, dataset9)\n",
    "api.ok(evaluation_ensemble_train9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train9['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train9['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train9['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test9 = api.create_evaluation(ensemble9, test_dataset)\n",
    "api.ok(evaluation_ensemble_test9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test9['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test9['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test9['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train9 = api.create_evaluation(deepnet9, dataset9)\n",
    "api.ok(evaluation_deepnet_train9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train9['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train9['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train9['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test9 = api.create_evaluation(deepnet9, test_dataset)\n",
    "api.ok(evaluation_deepnet_test9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test9['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test9['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test9['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train10 = api.create_evaluation(ensemble10, dataset10)\n",
    "api.ok(evaluation_ensemble_train10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train10['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train10['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train10['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test10 = api.create_evaluation(ensemble10, test_dataset)\n",
    "api.ok(evaluation_ensemble_test10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test10['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test10['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test10['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train10 = api.create_evaluation(deepnet10, dataset10)\n",
    "api.ok(evaluation_deepnet_train10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train10['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train10['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train10['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test10 = api.create_evaluation(deepnet10, test_dataset)\n",
    "api.ok(evaluation_deepnet_test10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test10['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test10['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test10['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train11 = api.create_evaluation(ensemble11, dataset11)\n",
    "api.ok(evaluation_ensemble_train11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train1['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train11['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train11['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test11 = api.create_evaluation(ensemble11, test_dataset)\n",
    "api.ok(evaluation_ensemble_test11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test11['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test11['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test11['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train11 = api.create_evaluation(deepnet11, dataset11)\n",
    "api.ok(evaluation_deepnet_train11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train11['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train11['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train11['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test11 = api.create_evaluation(deepnet11, test_dataset)\n",
    "api.ok(evaluation_deepnet_test11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test11['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test11['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test11['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train12 = api.create_evaluation(ensemble12, dataset12)\n",
    "api.ok(evaluation_ensemble_train12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train12['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train12['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train12['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test12 = api.create_evaluation(ensemble12, test_dataset)\n",
    "api.ok(evaluation_ensemble_test12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test12['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test12['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test12['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train12 = api.create_evaluation(deepnet12, dataset12)\n",
    "api.ok(evaluation_deepnet_train12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train12['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train12['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train12['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test12 = api.create_evaluation(deepnet12, test_dataset)\n",
    "api.ok(evaluation_deepnet_test12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test12['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test12['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test12['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train13 = api.create_evaluation(ensemble13, dataset13)\n",
    "api.ok(evaluation_ensemble_train13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train13['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train13['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train13['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test13 = api.create_evaluation(ensemble13, test_dataset)\n",
    "api.ok(evaluation_ensemble_test13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test13['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test13['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test13['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train13 = api.create_evaluation(deepnet13, dataset13)\n",
    "api.ok(evaluation_deepnet_train13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train13['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train13['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train13['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test13 = api.create_evaluation(deepnet13, test_dataset)\n",
    "api.ok(evaluation_deepnet_test13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test13['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test13['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test13['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train14 = api.create_evaluation(ensemble14, dataset14)\n",
    "api.ok(evaluation_ensemble_train14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train14['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train14['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train14['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test14 = api.create_evaluation(ensemble14, test_dataset)\n",
    "api.ok(evaluation_ensemble_test14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test14['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test14['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test14['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train14 = api.create_evaluation(deepnet14, dataset14)\n",
    "api.ok(evaluation_deepnet_train14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train14['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train14['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train14['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test14 = api.create_evaluation(deepnet14, test_dataset)\n",
    "api.ok(evaluation_deepnet_test14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test14['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test14['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test14['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train15 = api.create_evaluation(ensemble15, dataset15)\n",
    "api.ok(evaluation_ensemble_train15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train15['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train15['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train15['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test15 = api.create_evaluation(ensemble15, test_dataset)\n",
    "api.ok(evaluation_ensemble_test15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test15['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test15['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test15['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train15 = api.create_evaluation(deepnet15, dataset15)\n",
    "api.ok(evaluation_deepnet_train15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train15['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train15['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train15['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test15 = api.create_evaluation(deepnet15, test_dataset)\n",
    "api.ok(evaluation_deepnet_test15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test15['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test15['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test15['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train16 = api.create_evaluation(ensemble16, dataset16)\n",
    "api.ok(evaluation_ensemble_train16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train16['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train16['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train16['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test16 = api.create_evaluation(ensemble16, test_dataset)\n",
    "api.ok(evaluation_ensemble_test16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test16['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test16['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test16['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train16 = api.create_evaluation(deepnet16, dataset16)\n",
    "api.ok(evaluation_deepnet_train16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train16['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train16['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train16['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test16 = api.create_evaluation(deepnet16, test_dataset)\n",
    "api.ok(evaluation_deepnet_test16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test16['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test16['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test16['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train17 = api.create_evaluation(ensemble17, dataset17)\n",
    "api.ok(evaluation_ensemble_train17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train17['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train17['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train17['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test17 = api.create_evaluation(ensemble17, test_dataset)\n",
    "api.ok(evaluation_ensemble_test17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test17['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test17['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test17['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train17 = api.create_evaluation(deepnet17, dataset17)\n",
    "api.ok(evaluation_deepnet_train17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train17['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train17['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train17['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test17 = api.create_evaluation(deepnet17, test_dataset)\n",
    "api.ok(evaluation_deepnet_test17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test17['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test17['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test17['object']['result']['model']['average_area_under_roc_curve'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train18 = api.create_evaluation(ensemble18, dataset18)\n",
    "api.ok(evaluation_ensemble_train18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train18['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train18['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train18['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test18 = api.create_evaluation(ensemble18, test_dataset)\n",
    "api.ok(evaluation_ensemble_test18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test18['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test18['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test18['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train18 = api.create_evaluation(deepnet18, dataset18)\n",
    "api.ok(evaluation_deepnet_train18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train18['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train18['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train18['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test18 = api.create_evaluation(deepnet18, test_dataset)\n",
    "api.ok(evaluation_deepnet_test18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test18['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test18['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test18['object']['result']['model']['average_area_under_roc_curve'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train19 = api.create_evaluation(ensemble19, dataset19)\n",
    "api.ok(evaluation_ensemble_train19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train19['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train19['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train19['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test19 = api.create_evaluation(ensemble19, test_dataset)\n",
    "api.ok(evaluation_ensemble_test19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test19['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test19['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test19['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train19 = api.create_evaluation(deepnet19, dataset19)\n",
    "api.ok(evaluation_deepnet_train19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train19['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train19['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train19['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test19 = api.create_evaluation(deepnet19, test_dataset)\n",
    "api.ok(evaluation_deepnet_test19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test19['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test19['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test19['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_train20 = api.create_evaluation(ensemble20, dataset20)\n",
    "api.ok(evaluation_ensemble_train20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_evaluations.append(evaluation_ensemble_train20['resource'])\n",
    "ensemble_train_accuracy.append(evaluation_ensemble_train20['object']['result']['model']['accuracy'])\n",
    "ensemble_train_auc.append(evaluation_ensemble_train20['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_ensemble_test20 = api.create_evaluation(ensemble20, test_dataset)\n",
    "api.ok(evaluation_ensemble_test20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_evaluations.append(evaluation_ensemble_test20['resource'])\n",
    "ensemble_test_accuracy.append(evaluation_ensemble_test20['object']['result']['model']['accuracy'])\n",
    "ensemble_test_auc.append(evaluation_ensemble_test20['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_train20 = api.create_evaluation(deepnet20, dataset20)\n",
    "api.ok(evaluation_deepnet_train20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_evaluations.append(evaluation_deepnet_train20['resource'])\n",
    "deepnet_train_accuracy.append(evaluation_deepnet_train20['object']['result']['model']['accuracy'])\n",
    "deepnet_train_auc.append(evaluation_deepnet_train20['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the deepnet in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_deepnet_test20 = api.create_evaluation(deepnet20, test_dataset)\n",
    "api.ok(evaluation_deepnet_test20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_test_evaluations.append(evaluation_deepnet_test20['resource'])\n",
    "deepnet_test_accuracy.append(evaluation_deepnet_test20['object']['result']['model']['accuracy'])\n",
    "deepnet_test_auc.append(evaluation_deepnet_test20['object']['result']['model']['average_area_under_roc_curve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We export evaluations in a csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensemble_train_evaluations</th>\n",
       "      <th>ensemble_train_accuracy</th>\n",
       "      <th>ensemble_train_auc</th>\n",
       "      <th>ensemble_test_evaluations</th>\n",
       "      <th>ensemble_test_accuracy</th>\n",
       "      <th>ensemble_test_auc</th>\n",
       "      <th>deepnet_train_evaluations</th>\n",
       "      <th>deepnet_train_accuracy</th>\n",
       "      <th>deepnet_train_auc</th>\n",
       "      <th>deepnet_test_evaluations</th>\n",
       "      <th>deepnet_test_accuracy</th>\n",
       "      <th>deepnet_test_auc</th>\n",
       "      <th>nbr_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>dataset1</td>\n",
       "      <td>evaluation/5dbdc74ce47684746800fa15</td>\n",
       "      <td>0.96817</td>\n",
       "      <td>0.99730</td>\n",
       "      <td>evaluation/5dbdc7575299631c8200f0c5</td>\n",
       "      <td>0.93570</td>\n",
       "      <td>0.82158</td>\n",
       "      <td>evaluation/5dbdc89b5299632029005ddc</td>\n",
       "      <td>0.94150</td>\n",
       "      <td>0.89981</td>\n",
       "      <td>evaluation/5dbdc8c9e47684746800fa1e</td>\n",
       "      <td>0.93003</td>\n",
       "      <td>0.83789</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset2</td>\n",
       "      <td>evaluation/5dbdc8d27811dd7f2d00e7c5</td>\n",
       "      <td>0.95392</td>\n",
       "      <td>0.96955</td>\n",
       "      <td>evaluation/5dbdc8ef7811dd7f2d00e7c8</td>\n",
       "      <td>0.93637</td>\n",
       "      <td>0.84434</td>\n",
       "      <td>evaluation/5dbdc9015299632024000d3a</td>\n",
       "      <td>0.93867</td>\n",
       "      <td>0.86763</td>\n",
       "      <td>evaluation/5dbdc9337811dd7f2d00e7cb</td>\n",
       "      <td>0.93783</td>\n",
       "      <td>0.84743</td>\n",
       "      <td>12000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset3</td>\n",
       "      <td>evaluation/5dbdc93d5299631c8200f0c8</td>\n",
       "      <td>0.94811</td>\n",
       "      <td>0.94353</td>\n",
       "      <td>evaluation/5dbdc953e47684746800fa24</td>\n",
       "      <td>0.93827</td>\n",
       "      <td>0.84791</td>\n",
       "      <td>evaluation/5dbdc9855299631c8200f0cb</td>\n",
       "      <td>0.93478</td>\n",
       "      <td>0.85901</td>\n",
       "      <td>evaluation/5dbdc98de47684746800fa2a</td>\n",
       "      <td>0.93617</td>\n",
       "      <td>0.84605</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset4</td>\n",
       "      <td>evaluation/5dbdc9e05299631c8200f0ce</td>\n",
       "      <td>0.94404</td>\n",
       "      <td>0.92602</td>\n",
       "      <td>evaluation/5dbdc9f25299631c8200f0d4</td>\n",
       "      <td>0.93823</td>\n",
       "      <td>0.85969</td>\n",
       "      <td>evaluation/5dbdca3f5299631c8200f0d7</td>\n",
       "      <td>0.93288</td>\n",
       "      <td>0.86159</td>\n",
       "      <td>evaluation/5dbdca4be47684746800fa2d</td>\n",
       "      <td>0.93460</td>\n",
       "      <td>0.85327</td>\n",
       "      <td>24000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset5</td>\n",
       "      <td>evaluation/5dbdca5f5299631c8200f0da</td>\n",
       "      <td>0.94200</td>\n",
       "      <td>0.91796</td>\n",
       "      <td>evaluation/5dbdca715299631c8200f0dd</td>\n",
       "      <td>0.93843</td>\n",
       "      <td>0.85916</td>\n",
       "      <td>evaluation/5dbdca87e47684746800fa30</td>\n",
       "      <td>0.93463</td>\n",
       "      <td>0.86362</td>\n",
       "      <td>evaluation/5dbdca937811dd7f2d00e7ce</td>\n",
       "      <td>0.93727</td>\n",
       "      <td>0.85407</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset6</td>\n",
       "      <td>evaluation/5dbdcaae7811dd7f2d00e7d2</td>\n",
       "      <td>0.94233</td>\n",
       "      <td>0.91096</td>\n",
       "      <td>evaluation/5dbdcac55299631c8200f0e6</td>\n",
       "      <td>0.93823</td>\n",
       "      <td>0.86257</td>\n",
       "      <td>evaluation/5dbdcad9e47684746800fa33</td>\n",
       "      <td>0.93547</td>\n",
       "      <td>0.86105</td>\n",
       "      <td>evaluation/5dbdcae4e47684746800fa36</td>\n",
       "      <td>0.93690</td>\n",
       "      <td>0.85023</td>\n",
       "      <td>36000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset7</td>\n",
       "      <td>evaluation/5dbdcaf45299631c8200f0e9</td>\n",
       "      <td>0.94126</td>\n",
       "      <td>0.90468</td>\n",
       "      <td>evaluation/5dbdcb08e47684746800fa39</td>\n",
       "      <td>0.93923</td>\n",
       "      <td>0.86322</td>\n",
       "      <td>evaluation/5dbdcb245299632028000d79</td>\n",
       "      <td>0.93600</td>\n",
       "      <td>0.85974</td>\n",
       "      <td>evaluation/5dbdcb2fe47684746800fa3f</td>\n",
       "      <td>0.93690</td>\n",
       "      <td>0.85169</td>\n",
       "      <td>42000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset8</td>\n",
       "      <td>evaluation/5dbdcb5b7811dd7f2d00e7d5</td>\n",
       "      <td>0.94094</td>\n",
       "      <td>0.89986</td>\n",
       "      <td>evaluation/5dbdcb837811dd7f2d00e7d8</td>\n",
       "      <td>0.93900</td>\n",
       "      <td>0.86485</td>\n",
       "      <td>evaluation/5dbdcb9a5299632024000d3d</td>\n",
       "      <td>0.93238</td>\n",
       "      <td>0.85739</td>\n",
       "      <td>evaluation/5dbdcba65299632024000d40</td>\n",
       "      <td>0.93423</td>\n",
       "      <td>0.85353</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset9</td>\n",
       "      <td>evaluation/5dbdcbbe5299631de90011c2</td>\n",
       "      <td>0.93987</td>\n",
       "      <td>0.89504</td>\n",
       "      <td>evaluation/5dbdcbdd5299631c8200f0ec</td>\n",
       "      <td>0.93943</td>\n",
       "      <td>0.86699</td>\n",
       "      <td>evaluation/5dbdcbfb7811dd7f2d00e7db</td>\n",
       "      <td>0.93339</td>\n",
       "      <td>0.85015</td>\n",
       "      <td>evaluation/5dbdcc0de47684746800fa42</td>\n",
       "      <td>0.93667</td>\n",
       "      <td>0.84919</td>\n",
       "      <td>54000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset10</td>\n",
       "      <td>evaluation/5dbdcc4e7811dd7f2d00e7de</td>\n",
       "      <td>0.93987</td>\n",
       "      <td>0.89171</td>\n",
       "      <td>evaluation/5dbdcc6b5299631c8200f0ef</td>\n",
       "      <td>0.93910</td>\n",
       "      <td>0.86738</td>\n",
       "      <td>evaluation/5dbdcccf5299631c8200f0f8</td>\n",
       "      <td>0.93368</td>\n",
       "      <td>0.85056</td>\n",
       "      <td>evaluation/5dbdccde7811dd7f2d00e7e1</td>\n",
       "      <td>0.93663</td>\n",
       "      <td>0.85400</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset11</td>\n",
       "      <td>evaluation/5dbdc74ce47684746800fa15</td>\n",
       "      <td>0.93930</td>\n",
       "      <td>0.89097</td>\n",
       "      <td>evaluation/5dbdcd6fe47684746800fa48</td>\n",
       "      <td>0.93940</td>\n",
       "      <td>0.86745</td>\n",
       "      <td>evaluation/5dbdcd89e47684746800fa4b</td>\n",
       "      <td>0.93497</td>\n",
       "      <td>0.85289</td>\n",
       "      <td>evaluation/5dbdcda75299631c8200f0fb</td>\n",
       "      <td>0.93857</td>\n",
       "      <td>0.85183</td>\n",
       "      <td>66000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset12</td>\n",
       "      <td>evaluation/5dbdcdb0e47684746800fa4e</td>\n",
       "      <td>0.93931</td>\n",
       "      <td>0.88882</td>\n",
       "      <td>evaluation/5dbdcdd47811dd7f2d00e7e4</td>\n",
       "      <td>0.93960</td>\n",
       "      <td>0.86986</td>\n",
       "      <td>evaluation/5dbdcde55299631c8200f0fe</td>\n",
       "      <td>0.92814</td>\n",
       "      <td>0.85285</td>\n",
       "      <td>evaluation/5dbdcdfee47684746800fa51</td>\n",
       "      <td>0.93127</td>\n",
       "      <td>0.85800</td>\n",
       "      <td>72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset13</td>\n",
       "      <td>evaluation/5dbdce087811dd7f2d00e7e7</td>\n",
       "      <td>0.93959</td>\n",
       "      <td>0.88721</td>\n",
       "      <td>evaluation/5dbdce297811dd7f2d00e7ea</td>\n",
       "      <td>0.93933</td>\n",
       "      <td>0.86869</td>\n",
       "      <td>evaluation/5dbdce415299631c8200f101</td>\n",
       "      <td>0.93109</td>\n",
       "      <td>0.85291</td>\n",
       "      <td>evaluation/5dbdce51e47684746800fa54</td>\n",
       "      <td>0.93453</td>\n",
       "      <td>0.85647</td>\n",
       "      <td>78000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset14</td>\n",
       "      <td>evaluation/5dbdce5ee47684746800fa57</td>\n",
       "      <td>0.93936</td>\n",
       "      <td>0.88618</td>\n",
       "      <td>evaluation/5dbdce7de47684746800fa5a</td>\n",
       "      <td>0.93930</td>\n",
       "      <td>0.86748</td>\n",
       "      <td>evaluation/5dbdce945299632028000d7c</td>\n",
       "      <td>0.93515</td>\n",
       "      <td>0.85519</td>\n",
       "      <td>evaluation/5dbdcea3e47684746800fa5d</td>\n",
       "      <td>0.93883</td>\n",
       "      <td>0.85788</td>\n",
       "      <td>84000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset15</td>\n",
       "      <td>evaluation/5dbdcead7811dd7f2d00e7ed</td>\n",
       "      <td>0.93861</td>\n",
       "      <td>0.88422</td>\n",
       "      <td>evaluation/5dbdcecf5299631c8200f104</td>\n",
       "      <td>0.93957</td>\n",
       "      <td>0.86864</td>\n",
       "      <td>evaluation/5dbdcee87811dd055700146f</td>\n",
       "      <td>0.93589</td>\n",
       "      <td>0.85050</td>\n",
       "      <td>evaluation/5dbdcefc5299631c8200f107</td>\n",
       "      <td>0.93840</td>\n",
       "      <td>0.85487</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset16</td>\n",
       "      <td>evaluation/5dbdcf067811dd7f2d00e7f0</td>\n",
       "      <td>0.93859</td>\n",
       "      <td>0.88326</td>\n",
       "      <td>evaluation/5dbdcf287811dd7f2d00e7f3</td>\n",
       "      <td>0.93980</td>\n",
       "      <td>0.87005</td>\n",
       "      <td>evaluation/5dbdcf48e47684746800fa60</td>\n",
       "      <td>0.93078</td>\n",
       "      <td>0.84753</td>\n",
       "      <td>evaluation/5dbdcf5e7811dd7f2d00e7f6</td>\n",
       "      <td>0.93400</td>\n",
       "      <td>0.85204</td>\n",
       "      <td>96000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset17</td>\n",
       "      <td>evaluation/5dbdcf695299631c8200f10d</td>\n",
       "      <td>0.93845</td>\n",
       "      <td>0.88208</td>\n",
       "      <td>evaluation/5dbdcf937811dd7f2d00e7f9</td>\n",
       "      <td>0.93913</td>\n",
       "      <td>0.86994</td>\n",
       "      <td>evaluation/5dbdcfa27811dd7f2d00e7fc</td>\n",
       "      <td>0.93449</td>\n",
       "      <td>0.84575</td>\n",
       "      <td>evaluation/5dbdcfb25299632028000d7f</td>\n",
       "      <td>0.93743</td>\n",
       "      <td>0.85135</td>\n",
       "      <td>102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset18</td>\n",
       "      <td>evaluation/5dbdcfc05299631c8200f110</td>\n",
       "      <td>0.93877</td>\n",
       "      <td>0.88151</td>\n",
       "      <td>evaluation/5dbdcffae47684749e001031</td>\n",
       "      <td>0.93943</td>\n",
       "      <td>0.86782</td>\n",
       "      <td>evaluation/5dbdd0117811dd7f2d00e7ff</td>\n",
       "      <td>0.93539</td>\n",
       "      <td>0.85137</td>\n",
       "      <td>evaluation/5dbdd0267811dd7f2d00e802</td>\n",
       "      <td>0.93890</td>\n",
       "      <td>0.85454</td>\n",
       "      <td>108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset19</td>\n",
       "      <td>evaluation/5dbdd035e47684746800fa63</td>\n",
       "      <td>0.93858</td>\n",
       "      <td>0.88057</td>\n",
       "      <td>evaluation/5dbdd072e47684746800fa66</td>\n",
       "      <td>0.93920</td>\n",
       "      <td>0.86891</td>\n",
       "      <td>evaluation/5dbdd088e47684746800fa69</td>\n",
       "      <td>0.93641</td>\n",
       "      <td>0.85174</td>\n",
       "      <td>evaluation/5dbdd0997811dd7f2d00e805</td>\n",
       "      <td>0.93827</td>\n",
       "      <td>0.85559</td>\n",
       "      <td>114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset20</td>\n",
       "      <td>evaluation/5dbdd0a27811dd7f2d00e808</td>\n",
       "      <td>0.93872</td>\n",
       "      <td>0.87956</td>\n",
       "      <td>evaluation/5dbdd0c87811dd7f2d00e80b</td>\n",
       "      <td>0.93903</td>\n",
       "      <td>0.86956</td>\n",
       "      <td>evaluation/5dbdd0dae47684746800fa6c</td>\n",
       "      <td>0.93619</td>\n",
       "      <td>0.85076</td>\n",
       "      <td>evaluation/5dbdd100e47684746800fa6f</td>\n",
       "      <td>0.93860</td>\n",
       "      <td>0.85335</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ensemble_train_evaluations  ensemble_train_accuracy  \\\n",
       "dataset1   evaluation/5dbdc74ce47684746800fa15                  0.96817   \n",
       "dataset2   evaluation/5dbdc8d27811dd7f2d00e7c5                  0.95392   \n",
       "dataset3   evaluation/5dbdc93d5299631c8200f0c8                  0.94811   \n",
       "dataset4   evaluation/5dbdc9e05299631c8200f0ce                  0.94404   \n",
       "dataset5   evaluation/5dbdca5f5299631c8200f0da                  0.94200   \n",
       "dataset6   evaluation/5dbdcaae7811dd7f2d00e7d2                  0.94233   \n",
       "dataset7   evaluation/5dbdcaf45299631c8200f0e9                  0.94126   \n",
       "dataset8   evaluation/5dbdcb5b7811dd7f2d00e7d5                  0.94094   \n",
       "dataset9   evaluation/5dbdcbbe5299631de90011c2                  0.93987   \n",
       "dataset10  evaluation/5dbdcc4e7811dd7f2d00e7de                  0.93987   \n",
       "dataset11  evaluation/5dbdc74ce47684746800fa15                  0.93930   \n",
       "dataset12  evaluation/5dbdcdb0e47684746800fa4e                  0.93931   \n",
       "dataset13  evaluation/5dbdce087811dd7f2d00e7e7                  0.93959   \n",
       "dataset14  evaluation/5dbdce5ee47684746800fa57                  0.93936   \n",
       "dataset15  evaluation/5dbdcead7811dd7f2d00e7ed                  0.93861   \n",
       "dataset16  evaluation/5dbdcf067811dd7f2d00e7f0                  0.93859   \n",
       "dataset17  evaluation/5dbdcf695299631c8200f10d                  0.93845   \n",
       "dataset18  evaluation/5dbdcfc05299631c8200f110                  0.93877   \n",
       "dataset19  evaluation/5dbdd035e47684746800fa63                  0.93858   \n",
       "dataset20  evaluation/5dbdd0a27811dd7f2d00e808                  0.93872   \n",
       "\n",
       "           ensemble_train_auc            ensemble_test_evaluations  \\\n",
       "dataset1              0.99730  evaluation/5dbdc7575299631c8200f0c5   \n",
       "dataset2              0.96955  evaluation/5dbdc8ef7811dd7f2d00e7c8   \n",
       "dataset3              0.94353  evaluation/5dbdc953e47684746800fa24   \n",
       "dataset4              0.92602  evaluation/5dbdc9f25299631c8200f0d4   \n",
       "dataset5              0.91796  evaluation/5dbdca715299631c8200f0dd   \n",
       "dataset6              0.91096  evaluation/5dbdcac55299631c8200f0e6   \n",
       "dataset7              0.90468  evaluation/5dbdcb08e47684746800fa39   \n",
       "dataset8              0.89986  evaluation/5dbdcb837811dd7f2d00e7d8   \n",
       "dataset9              0.89504  evaluation/5dbdcbdd5299631c8200f0ec   \n",
       "dataset10             0.89171  evaluation/5dbdcc6b5299631c8200f0ef   \n",
       "dataset11             0.89097  evaluation/5dbdcd6fe47684746800fa48   \n",
       "dataset12             0.88882  evaluation/5dbdcdd47811dd7f2d00e7e4   \n",
       "dataset13             0.88721  evaluation/5dbdce297811dd7f2d00e7ea   \n",
       "dataset14             0.88618  evaluation/5dbdce7de47684746800fa5a   \n",
       "dataset15             0.88422  evaluation/5dbdcecf5299631c8200f104   \n",
       "dataset16             0.88326  evaluation/5dbdcf287811dd7f2d00e7f3   \n",
       "dataset17             0.88208  evaluation/5dbdcf937811dd7f2d00e7f9   \n",
       "dataset18             0.88151  evaluation/5dbdcffae47684749e001031   \n",
       "dataset19             0.88057  evaluation/5dbdd072e47684746800fa66   \n",
       "dataset20             0.87956  evaluation/5dbdd0c87811dd7f2d00e80b   \n",
       "\n",
       "           ensemble_test_accuracy  ensemble_test_auc  \\\n",
       "dataset1                  0.93570            0.82158   \n",
       "dataset2                  0.93637            0.84434   \n",
       "dataset3                  0.93827            0.84791   \n",
       "dataset4                  0.93823            0.85969   \n",
       "dataset5                  0.93843            0.85916   \n",
       "dataset6                  0.93823            0.86257   \n",
       "dataset7                  0.93923            0.86322   \n",
       "dataset8                  0.93900            0.86485   \n",
       "dataset9                  0.93943            0.86699   \n",
       "dataset10                 0.93910            0.86738   \n",
       "dataset11                 0.93940            0.86745   \n",
       "dataset12                 0.93960            0.86986   \n",
       "dataset13                 0.93933            0.86869   \n",
       "dataset14                 0.93930            0.86748   \n",
       "dataset15                 0.93957            0.86864   \n",
       "dataset16                 0.93980            0.87005   \n",
       "dataset17                 0.93913            0.86994   \n",
       "dataset18                 0.93943            0.86782   \n",
       "dataset19                 0.93920            0.86891   \n",
       "dataset20                 0.93903            0.86956   \n",
       "\n",
       "                     deepnet_train_evaluations  deepnet_train_accuracy  \\\n",
       "dataset1   evaluation/5dbdc89b5299632029005ddc                 0.94150   \n",
       "dataset2   evaluation/5dbdc9015299632024000d3a                 0.93867   \n",
       "dataset3   evaluation/5dbdc9855299631c8200f0cb                 0.93478   \n",
       "dataset4   evaluation/5dbdca3f5299631c8200f0d7                 0.93288   \n",
       "dataset5   evaluation/5dbdca87e47684746800fa30                 0.93463   \n",
       "dataset6   evaluation/5dbdcad9e47684746800fa33                 0.93547   \n",
       "dataset7   evaluation/5dbdcb245299632028000d79                 0.93600   \n",
       "dataset8   evaluation/5dbdcb9a5299632024000d3d                 0.93238   \n",
       "dataset9   evaluation/5dbdcbfb7811dd7f2d00e7db                 0.93339   \n",
       "dataset10  evaluation/5dbdcccf5299631c8200f0f8                 0.93368   \n",
       "dataset11  evaluation/5dbdcd89e47684746800fa4b                 0.93497   \n",
       "dataset12  evaluation/5dbdcde55299631c8200f0fe                 0.92814   \n",
       "dataset13  evaluation/5dbdce415299631c8200f101                 0.93109   \n",
       "dataset14  evaluation/5dbdce945299632028000d7c                 0.93515   \n",
       "dataset15  evaluation/5dbdcee87811dd055700146f                 0.93589   \n",
       "dataset16  evaluation/5dbdcf48e47684746800fa60                 0.93078   \n",
       "dataset17  evaluation/5dbdcfa27811dd7f2d00e7fc                 0.93449   \n",
       "dataset18  evaluation/5dbdd0117811dd7f2d00e7ff                 0.93539   \n",
       "dataset19  evaluation/5dbdd088e47684746800fa69                 0.93641   \n",
       "dataset20  evaluation/5dbdd0dae47684746800fa6c                 0.93619   \n",
       "\n",
       "           deepnet_train_auc             deepnet_test_evaluations  \\\n",
       "dataset1             0.89981  evaluation/5dbdc8c9e47684746800fa1e   \n",
       "dataset2             0.86763  evaluation/5dbdc9337811dd7f2d00e7cb   \n",
       "dataset3             0.85901  evaluation/5dbdc98de47684746800fa2a   \n",
       "dataset4             0.86159  evaluation/5dbdca4be47684746800fa2d   \n",
       "dataset5             0.86362  evaluation/5dbdca937811dd7f2d00e7ce   \n",
       "dataset6             0.86105  evaluation/5dbdcae4e47684746800fa36   \n",
       "dataset7             0.85974  evaluation/5dbdcb2fe47684746800fa3f   \n",
       "dataset8             0.85739  evaluation/5dbdcba65299632024000d40   \n",
       "dataset9             0.85015  evaluation/5dbdcc0de47684746800fa42   \n",
       "dataset10            0.85056  evaluation/5dbdccde7811dd7f2d00e7e1   \n",
       "dataset11            0.85289  evaluation/5dbdcda75299631c8200f0fb   \n",
       "dataset12            0.85285  evaluation/5dbdcdfee47684746800fa51   \n",
       "dataset13            0.85291  evaluation/5dbdce51e47684746800fa54   \n",
       "dataset14            0.85519  evaluation/5dbdcea3e47684746800fa5d   \n",
       "dataset15            0.85050  evaluation/5dbdcefc5299631c8200f107   \n",
       "dataset16            0.84753  evaluation/5dbdcf5e7811dd7f2d00e7f6   \n",
       "dataset17            0.84575  evaluation/5dbdcfb25299632028000d7f   \n",
       "dataset18            0.85137  evaluation/5dbdd0267811dd7f2d00e802   \n",
       "dataset19            0.85174  evaluation/5dbdd0997811dd7f2d00e805   \n",
       "dataset20            0.85076  evaluation/5dbdd100e47684746800fa6f   \n",
       "\n",
       "           deepnet_test_accuracy  deepnet_test_auc  nbr_data  \n",
       "dataset1                 0.93003           0.83789      6000  \n",
       "dataset2                 0.93783           0.84743     12000  \n",
       "dataset3                 0.93617           0.84605     18000  \n",
       "dataset4                 0.93460           0.85327     24000  \n",
       "dataset5                 0.93727           0.85407     30000  \n",
       "dataset6                 0.93690           0.85023     36000  \n",
       "dataset7                 0.93690           0.85169     42000  \n",
       "dataset8                 0.93423           0.85353     48000  \n",
       "dataset9                 0.93667           0.84919     54000  \n",
       "dataset10                0.93663           0.85400     60000  \n",
       "dataset11                0.93857           0.85183     66000  \n",
       "dataset12                0.93127           0.85800     72000  \n",
       "dataset13                0.93453           0.85647     78000  \n",
       "dataset14                0.93883           0.85788     84000  \n",
       "dataset15                0.93840           0.85487     90000  \n",
       "dataset16                0.93400           0.85204     96000  \n",
       "dataset17                0.93743           0.85135    102000  \n",
       "dataset18                0.93890           0.85454    108000  \n",
       "dataset19                0.93827           0.85559    114000  \n",
       "dataset20                0.93860           0.85335    120000  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_deep_ens = DataFrame({'ensemble_train_evaluations' : ensemble_train_evaluations, 'ensemble_train_accuracy': ensemble_train_accuracy, 'ensemble_train_auc': ensemble_train_auc, 'ensemble_test_evaluations' : ensemble_test_evaluations, 'ensemble_test_accuracy': ensemble_test_accuracy, 'ensemble_test_auc': ensemble_test_auc,\n",
    "                                'deepnet_train_evaluations' : deepnet_train_evaluations, 'deepnet_train_accuracy': deepnet_train_accuracy, 'deepnet_train_auc': deepnet_train_auc,'deepnet_test_evaluations' : deepnet_test_evaluations, 'deepnet_test_accuracy': deepnet_test_accuracy, 'deepnet_test_auc': deepnet_test_auc, 'nbr_data' : bigml_infos['nbr_data']})\n",
    "\n",
    "eval_deep_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_deep_ens.to_csv(r'dataset_deepnet_ensemble/bigml/bigml_evaluations.csv',  header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
