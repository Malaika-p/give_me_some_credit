{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap de la manip kaggle (general contest):\n",
    "\n",
    "\n",
    "* analyse du sujet\n",
    "* recuperer le train data set et le test data set (a submitter à kaggle)\n",
    "* lecture des features et reperer la target "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On importe les librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, read_csv\n",
    "import bigml.api\n",
    "from bigml.api import BigML\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Importer les data set CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "!ls\n",
    "fulltrain=read_csv('./cs-training.csv', index_col=0)\n",
    "test=read_csv('./cs-test.csv', index_col=0)\n",
    "fulltrain.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Realisation d'un split de 80/20 sur le train full de kaggle afin d'entrainer un modele\n",
    "* On a donc un Train set (80%) et un Dev set(20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, dev_set = train_dev_split(fulltrain, test_size=0.2)\n",
    "\n",
    "export_csv = dev_set.to_csv (r'dev_set.csv',  header=True) \n",
    "export_csv = training_set.to_csv (r'training_set.csv',  header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modele\n",
    "* Sur BigML\n",
    "  * On créer une source\n",
    "  * On créer un data set depuit la source \n",
    "  * On créer notre modèle (ici ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = api.create_source('training_set.csv')\n",
    "# waiting for the source to be finished. Results will be stored in `source`\n",
    "api.ok(source)\n",
    "# step 3: creating a dataset from the previously created `source`\n",
    "dataset = api.create_dataset(source)\n",
    "# waiting for the dataset to be finished\n",
    "api.ok(dataset) \n",
    "# step 5: creating an Ensemble\n",
    "ensemble1 = api.create_ensemble(dataset)\n",
    "# waiting for the ensemble to be finished\n",
    "api.ok(ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  On fait une évaluation du modèle\n",
    "\n",
    "* on regarde les summury report pour voir quels features on été le plus utilisés par le modele.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = ensemble['object']['importance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* refabriquer un dictionnaire avec les noms de colonnes (et non plus les n°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importances_named = dict()\n",
    "for column, importance in importances.items():\n",
    "    column_name = ensemble['object']['ensemble']['fields'][column]['name']\n",
    "    importances_named[column_name] = importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* on fait une batchprediction de notre modèle sur le dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6: creating a source from the data in your local \"data/test_iris.csv\" file\n",
    "dev_source = api.create_source(\"dev_set.csv\")\n",
    "# waiting for the source to be finished. Results will be stored in `source`\n",
    "api.ok(dev_source)\n",
    "# step 8: creating a dataset from the previously created `source`\n",
    "dev_dataset = api.create_dataset(dev_source)\n",
    "# waiting for the dataset to be finished\n",
    "api.ok(dev_dataset)\n",
    "# step 10: creating a batch prediction\n",
    "batch_prediction = api.create_batch_prediction(ensemble, dev_dataset,\n",
    "                                               {\"all_fields\": True})\n",
    "# waiting for the batch_prediction to be finished\n",
    "api.ok(batch_prediction)\n",
    "# downloading the results to your computer\n",
    "api.download_batch_prediction(batch_prediction,\n",
    "                              filename='predictions/my_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## on créer l'evaluation\n",
    "* On regarde les matrices de confusions, l AUC, Accuracy... afin de comprendre la precision du modele.\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_dataset = api.create_dataset(test_source)\n",
    "api.ok(test_dataset)\n",
    "evaluation = api.create_evaluation(ensemble, test_dataset)\n",
    "api.ok(evaluation)\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* on adapte nos data set en ajoutant des features, ponderant, etc... en se basant sur le summary report precedent.\n",
    "  * On peut egalement changer de modele\n",
    "  * on peut faire varier les splits ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lorsque que l'on est satisfait de notre modele de prediction\n",
    "\n",
    "* On peut entrainer notre modele sur le train full pour augmenter sa capacité à généraliser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = api.create_source('training_full.csv')\n",
    "# waiting for the source to be finished. Results will be stored in `source`\n",
    "api.ok(source)\n",
    "# step 3: creating a dataset from the previously created `source`\n",
    "dataset = api.create_dataset(source)\n",
    "# waiting for the dataset to be finished\n",
    "api.ok(dataset) \n",
    "# step 5: creating an Ensemble\n",
    "ensemble = api.create_ensemble(dataset)\n",
    "# waiting for the ensemble to be finished\n",
    "api.ok(ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On applique le modele obtenu  sur le test (fichier kaggle)\n",
    "* on enregristre en csv le resultat test full avec la colonne de prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'predictions/my_predictions3.csv'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# step 6: creating a source from the data in your local \"data/test_iris.csv\" file\n",
    "test_source = api.create_source(\"test_set.csv\")\n",
    "# waiting for the source to be finished. Results will be stored in `source`\n",
    "api.ok(test_source)\n",
    "# step 8: creating a dataset from the previously created `source`\n",
    "test_dataset = api.create_dataset(test_source)\n",
    "# waiting for the dataset to be finished\n",
    "api.ok(test_dataset)\n",
    "# step 10: creating a batch prediction\n",
    "batch_prediction = api.create_batch_prediction(ensemblefull, validation_dataset,\n",
    "                                               {\"all_fields\": True,\n",
    "                                                \"header\": True,\n",
    "                                                \"confidence\": True,\n",
    "                                                \"probabilities\": True})\n",
    "# waiting for the batch_prediction to be finished\n",
    "api.ok(batch_prediction)\n",
    "# downloading the results to your computer\n",
    "api.download_batch_prediction(batch_prediction,\n",
    "                              filename='predictions/my_predictions_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* on mets en forme le fichier selon la demande de kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['field1', 'RevolvingUtilizationOfUnsecuredLines', 'age', 'DebtRatio', 'MonthlyIncome', 'MonthlyDebt', 'DisposableIncome', 'BalancedIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberRealEstateLoansOrLines', 'NumberOfTime30-59DaysPastDueNotWorse', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfTimes90DaysLate', 'WeightedOfLatePayment', 'NumberOfDependents', 'SeriousDlqin2yrs', 'SeriousDlqin2yrs.1', 'confidence', '0 probability', '1 probability']\n"
     ]
    }
   ],
   "source": [
    "prediction=read_csv('predictions/my_predictions_test.csv',index_col=False)\n",
    "print(list(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_prediction=DataFrame()\n",
    "kaggle_prediction['Id']=prediction['field1']\n",
    "kaggle_prediction['Probability']=prediction['1 probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.03826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.09709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.13328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Probability\n",
       "0   1      0.05203\n",
       "1   2      0.03826\n",
       "2   3      0.00986\n",
       "3   4      0.09709\n",
       "4   5      0.13328"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* on upload le csv sur kaggle pour decouvrir le score de prediction et le leader board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:05<00:00, 333kB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to Give Me Some Credit"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_prediction_file=\"kaggleprediction.csv\"\n",
    "kaggle_prediction.to_csv(kaggle_prediction_file,index=False)\n",
    "kaggle.api.competition_submit(kaggle_prediction_file, \"Prediction Bigml\", \"GiveMeSomeCredit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maud, Maxime, Laurent, Christophe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
